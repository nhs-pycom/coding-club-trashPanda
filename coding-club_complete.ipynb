{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "coding-club.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhs-pycom/coding-club-trashPanda/blob/main/coding-club_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9K3whwtYBFr"
      },
      "source": [
        "# Welcome to NHSX Coding Club\r\n",
        "\r\n",
        "## Lesson One: trashPanda\r\n",
        "\r\n",
        "### Pandas for excel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-ZQGbA4YUPb"
      },
      "source": [
        "# clone coding club repo to google colab\r\n",
        "!git clone -l -s git://github.com/nhs-pycom/coding-club-trashPanda.git cloned-repo\r\n",
        "%cd cloned-repo\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yoSwdH7ZZ0k"
      },
      "source": [
        "import pandas as pd\r\n",
        "pd.set_option(\"display.max.columns\", None) # show all columns in dataframe\r\n",
        "\r\n",
        "# read an excel file from repo /data/ folder\r\n",
        "path = '/content/cloned-repo/data/tabular structure/Q1 Returns/Jan 2021.xlsx'\r\n",
        "df = pd.read_excel(path)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_7vhDULcex4"
      },
      "source": [
        "# specify which sheet to load and index column number (remember index starts at 0 in python)\r\n",
        "df = pd.read_excel(path, sheet_name=0, index_col=0)\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx5VJiHLdkmI"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ8lIm_teN6O"
      },
      "source": [
        "# basic transformations\r\n",
        "sort_population = df.sort_values(['Population:'], ascending=False)\r\n",
        "sort_population['Population:']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nByE0EofIkC"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# bar chart\r\n",
        "sort_population['Population:'].plot(kind=\"barh\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TAzHyENfs-R"
      },
      "source": [
        "# discriptive statistics\r\n",
        "sort_population['Population:'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThChiIlhKBt5"
      },
      "source": [
        "# parse excel file as object\r\n",
        "excel_file = pd.ExcelFile(path)\r\n",
        "excel_file.sheet_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xY1OYfodMYNg"
      },
      "source": [
        "# parse sheet in excel file from sheet names list\r\n",
        "excel_file.parse(excel_file.sheet_names[0]).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R18MfLEoLXTx"
      },
      "source": [
        "# loop through sheets and concatanate them together\r\n",
        "temp_list = []\r\n",
        "for sheet in excel_file.sheet_names:\r\n",
        "   temp_list.append(excel_file.parse(sheet))\r\n",
        "all_df = pd.concat(temp_list)\r\n",
        "all_df.reset_index(drop=True, inplace=True) # reset index\r\n",
        "all_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARQlzgzWNDbr"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "path = \"/content/cloned-repo/data/tabular structure/\"\r\n",
        "my_filenames = [\r\n",
        "    os.path.join(root, name) # join root folder and name of file\r\n",
        "    for root, dirs, files in os.walk(path) # for all files and directories in path\r\n",
        "    for name in files\r\n",
        "    if name.endswith((\".xlsx\")) # that end with .xlsx (excel files)\r\n",
        "]\r\n",
        "my_filenames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62OjOg72Qbwx"
      },
      "source": [
        "from fnmatch import fnmatch\r\n",
        "\r\n",
        "temp_list = []\r\n",
        "\r\n",
        "for filename in my_filenames:\r\n",
        "    excel_file = pd.ExcelFile(filename)\r\n",
        "    # filter out non-data sheets by calling those with 'CCG' in name\r\n",
        "    sheet_list = [sheet for sheet in excel_file.sheet_names if fnmatch(sheet, \"*CCG*\")]\r\n",
        "    for sheet in excel_file.sheet_names:\r\n",
        "      temp_list.append(excel_file.parse(sheet)) # parse each sheet into list\r\n",
        "all_df = pd.concat(temp_list)\r\n",
        "all_df.reset_index(drop=True, inplace=True) # reset index\r\n",
        "all_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWF7rzy6WKUR"
      },
      "source": [
        "temp_list = []\r\n",
        "\r\n",
        "for filename in my_filenames:\r\n",
        "    excel_file = pd.ExcelFile(filename)\r\n",
        "    # filter out non-data sheets by calling those with 'CCG' in name\r\n",
        "    sheet_list = [sheet for sheet in excel_file.sheet_names if fnmatch(sheet, \"*CCG*\")]\r\n",
        "    for sheet in excel_file.sheet_names:\r\n",
        "      temp_list.append(excel_file.parse(sheet)) # parse each sheet into list\r\n",
        "df = pd.concat(temp_list)\r\n",
        "df.reset_index(drop=True, inplace=True) # reset index\r\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLGyKMFczaa"
      },
      "source": [
        "df.to_csv(r'data/output.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAZAlv9cGSMW"
      },
      "source": [
        "# trashPanda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpFBpibGPm6O"
      },
      "source": [
        "from openpyxl import load_workbook\r\n",
        "\r\n",
        "path = '/content/cloned-repo/data/poor structure/Q1 Returns/Jan 2021.xlsx'\r\n",
        "# Load in the workbook\r\n",
        "wb = load_workbook(path)\r\n",
        "\r\n",
        "# Get sheet names\r\n",
        "print(wb.sheetnames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi39i13HPm6T"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# last modified datex\n",
        "time_stamp = os.path.getmtime(path)\n",
        "print(time_stamp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rzllSftPm6T"
      },
      "source": [
        "# last modified date\n",
        "mod_date = datetime.fromtimestamp(time_stamp).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(mod_date)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c92QGKBTPm6U"
      },
      "source": [
        "# trashPanda function\n",
        "import os\n",
        "import pandas as pd\n",
        "from openpyxl import load_workbook\n",
        "from datetime import datetime\n",
        "from fnmatch import fnmatch\n",
        "\n",
        "\n",
        "def trashPanda(path):\n",
        "    \"\"\"Searches directories for excel files, extracts data and returns a structured pandas dataframe.\"\"\"\n",
        "    my_filenames = [\n",
        "        os.path.join(root, name)\n",
        "        for root, dirs, files in os.walk(path)\n",
        "        for name in files\n",
        "        if name.endswith((\".xlsx\"))\n",
        "    ]\n",
        "    df = pd.DataFrame(\n",
        "        columns=[\n",
        "            \"file\",\n",
        "            \"mod_date\",\n",
        "            \"sheet\",\n",
        "            \"Org name\",\n",
        "            \"Area Name\",\n",
        "            \"Completed by\",\n",
        "            \"Date completed\",\n",
        "            \"Population\",\n",
        "            \"Number of Records\",\n",
        "            \"Number of Users\",\n",
        "            \"Number of Views\",\n",
        "            \"Number of Deployments\",\n",
        "            \"Number of Unique Users\",\n",
        "            \"Name of Errors\",\n",
        "        ]\n",
        "    )\n",
        "    for filename in my_filenames:\n",
        "        wb = load_workbook(filename)\n",
        "        sheet_list = [\n",
        "            sheet for sheet in wb.sheetnames if fnmatch(sheet, \"*CCG*\")\n",
        "        ]\n",
        "        # last modified date\n",
        "        mod_date = datetime.fromtimestamp(os.path.getmtime(filename)).strftime(\n",
        "            \"%Y-%m-%d\"\n",
        "        )\n",
        "        for sheet in sheet_list:\n",
        "            df = df.append(\n",
        "                {\n",
        "                    \"file\": filename,\n",
        "                    \"mod_date\": mod_date,\n",
        "                    \"sheet\": wb[sheet].title,\n",
        "                    \"Org name\": wb[sheet][\"B1\"].value,\n",
        "                    \"Area Name\": wb[sheet][\"D1\"].value,\n",
        "                    \"Completed by\": wb[sheet][\"B4\"].value,\n",
        "                    \"Date completed\": wb[sheet][\"D4\"].value,\n",
        "                    \"Population\": wb[sheet][\"B2\"].value,\n",
        "                    \"Number of Records\": wb[sheet][\"D2\"].value,\n",
        "                    \"Number of Users\": wb[sheet][\"B3\"].value,\n",
        "                    \"Number of Views\": wb[sheet][\"D3\"].value,\n",
        "                    \"Number of Deployments\": wb[sheet][\"B5\"].value,\n",
        "                    \"Number of Unique Users\": wb[sheet][\"B6\"].value,\n",
        "                    \"Number of Errors\": wb[sheet][\"D6\"].value,\n",
        "                },\n",
        "                ignore_index=True,\n",
        "            )\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EOzZFfxFkTM"
      },
      "source": [
        "# call function\r\n",
        "path = \"/content/cloned-repo/data/poor structure/\"\r\n",
        "df = trashPanda(path)\r\n",
        "df.to_csv(r'data/output.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CVett8rGNWR"
      },
      "source": [
        "# Fuzzywuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJEAMyAPSzUI"
      },
      "source": [
        "!pip install fuzzywuzzy\r\n",
        "!pip install -U PyYAML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MRsKJZakPzw"
      },
      "source": [
        "import os\r\n",
        "import yaml\r\n",
        "import pandas as pd\r\n",
        "from openpyxl import load_workbook\r\n",
        "from datetime import datetime\r\n",
        "from fnmatch import fnmatch\r\n",
        "from fuzzywuzzy import process\r\n",
        "from fuzzywuzzy import fuzz\r\n",
        "\r\n",
        "config = 'config.yaml'\r\n",
        "with open(config, \"r\") as yamlfile:\r\n",
        "    configs = yaml.load(yamlfile, Loader=yaml.FullLoader)\r\n",
        "\r\n",
        "path = \"data/poor structure\"\r\n",
        "df = pd.DataFrame(columns=configs['Column Names'])\r\n",
        "dictionary = {}\r\n",
        "limit = 1   # Number of results to return\r\n",
        "cutoff = 80 # % similarity\r\n",
        "\r\n",
        "my_filenames = [\r\n",
        "    os.path.join(root, name)\r\n",
        "    for root, dirs, files in os.walk(path)\r\n",
        "    for name in files\r\n",
        "    if name.endswith((\".xlsx\"))\r\n",
        "]\r\n",
        "# loop files\r\n",
        "for filename in my_filenames:\r\n",
        "    wb = load_workbook(filename)\r\n",
        "    dictionary[\"file\"] = filename\r\n",
        "    sheet_list = [sheet for sheet in wb.sheetnames if fnmatch(sheet, configs[\"Sheet\"])]\r\n",
        "    # last modified date\r\n",
        "    mod_date = datetime.fromtimestamp(os.path.getmtime(filename))\r\n",
        "    dictionary[\"Modified date\"] = mod_date\r\n",
        "    # loop sheets\r\n",
        "    for sheet in sheet_list:\r\n",
        "        dictionary[\"sheet\"] = sheet\r\n",
        "        df_sheet = pd.read_excel(\r\n",
        "            filename,\r\n",
        "            sheet_name=sheet,\r\n",
        "            engine=\"openpyxl\",\r\n",
        "            index_col=None,\r\n",
        "            header=None,\r\n",
        "            nrows=configs[\"Rows\"],\r\n",
        "        )\r\n",
        "        for row in list(range(0, configs[\"Rows\"])):\r\n",
        "            for name in configs['Column Names']:\r\n",
        "                match = process.extractBests(\r\n",
        "                    name,\r\n",
        "                    df_sheet.iloc[row],\r\n",
        "                    limit=limit,\r\n",
        "                    scorer=fuzz.token_sort_ratio,\r\n",
        "                    score_cutoff=cutoff,\r\n",
        "                )\r\n",
        "                if match:\r\n",
        "                    location = [i for i, x in enumerate(df_sheet.iloc[row] == match[0][0]) if x]\r\n",
        "                    result = df_sheet.iloc[row][location[0]+1]\r\n",
        "                    dictionary[name] = result\r\n",
        "        df = df.append(dictionary, ignore_index=True)\r\n",
        "df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}